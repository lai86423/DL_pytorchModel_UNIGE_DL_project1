{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PT_5.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"vkDYova_0FSe","executionInfo":{"status":"ok","timestamp":1636544974207,"user_tz":-60,"elapsed":532,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"7b7aea2a-729b-4eda-cdf0-dcc3a17a501f"},"source":["from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive\"     # default location for the drive\n","print(ROOT)                 # print content of ROOT (Optional)\n","\n","drive.mount(ROOT)    \n","\n","%cd '/content/drive/My Drive/UNIGE/Course/Deep Learning/final project/'\n","%pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/UNIGE/Course/Deep Learning/final project\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/UNIGE/Course/Deep Learning/final project'"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvrQwn9f0mHh","executionInfo":{"status":"ok","timestamp":1636541683386,"user_tz":-60,"elapsed":311,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"f6f56a99-830d-4ec4-9bb6-92b7af02cadc"},"source":["%cd /content/drive/My Drive/UNIGE/Course/Deep Learning/final project/\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/UNIGE/Course/Deep Learning/final project\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnSuFxr0eJNw","executionInfo":{"status":"ok","timestamp":1636541692376,"user_tz":-60,"elapsed":317,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"f66ab0ff-7e61-4f0b-9daa-61a8fea0a0bf"},"source":["%ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2111.YRLai-mobility.en.zh-TW.pdf  2111.YRLai-mobility.pdf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvRDhg23f0i5","executionInfo":{"status":"ok","timestamp":1636545100611,"user_tz":-60,"elapsed":407,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"cb421af2-b72d-4370-e978-1c42f2da9ec6"},"source":["# Clone github repository setup\n","# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n","from os.path import join  \n","\n","# path to your project on Google Drive\n","MY_GOOGLE_DRIVE_PATH = '/content/drive/My Drive/UNIGE/Course/Deep Learning/final project/unige_DL_project1/' \n","# replace with your Github username \n","GIT_USERNAME = \"lai86423\" \n","# definitely replace with your\n","GIT_TOKEN = \"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\"  \n","# Replace with your github repository in this case we want \n","# to clone deep-learning-v2-pytorch repository\n","GIT_REPOSITORY = \"unige_DL_project1\" \n","\n","PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n","\n","# It's good to print out the value if you are not sure \n","print(\"PROJECT_PATH: \", PROJECT_PATH)   \n","\n","# In case we haven't created the folder already; we will create a folder in the project path \n","!mkdir \"{PROJECT_PATH}\"    \n","\n","#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n","GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n","print(\"GIT_PATH: \", GIT_PATH)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PROJECT_PATH:  /content/drive/My Drive/UNIGE/Course/Deep Learning/final project/unige_DL_project1/\n","mkdir: cannot create directory ‘/content/drive/My Drive/UNIGE/Course/Deep Learning/final project/unige_DL_project1/’: File exists\n","GIT_PATH:  https://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@github.com/lai86423/unige_DL_project1.git\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9Kk8PfThfiM","executionInfo":{"status":"ok","timestamp":1636544686860,"user_tz":-60,"elapsed":1370,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"87d7d0ea-d08b-4e5b-f6ca-31384b267546"},"source":["#%cd \"{PROJECT_PATH}\"\n","#%cd '/unige_DL_project_1'   # Change directory to the location defined in project_path\\\n","%cd \"{PROJECT_PATH}\"    # Change directory to the location defined in project_path\n","!git clone \"{GIT_PATH}\" # clone the github repository"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/My Drive/UNIGE/Course/Deep Learning/final project/unige_DL_project_1/ # Change directory to the location defined in project_path'\n","/content/drive/My Drive/UNIGE/Course/Deep Learning/final project\n","Cloning into 'unige_DL_project1'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (3/3), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aH1om7rrMi0","executionInfo":{"status":"ok","timestamp":1636545165945,"user_tz":-60,"elapsed":526,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"08825c84-6f44-402f-e796-88ff962b17e4"},"source":["%cd \"{PROJECT_PATH}\" \n","%pwd\n","!git branch\n","!git status"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/UNIGE/Course/Deep Learning/final project/unige_DL_project1\n","* \u001b[32mmain\u001b[m\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwiMhzQO1mnI","executionInfo":{"status":"ok","timestamp":1636547665695,"user_tz":-60,"elapsed":255,"user":{"displayName":"Irene Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgupWfHLvBhu3UAYl9P1SF7ugKmvEEWWu6f68LcdjM=s64","userId":"07354231171708526539"}},"outputId":"3f66709d-c365-4c1a-9106-4349e52054f4"},"source":["print(\"hi\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hi\n","fatal: not a git repository (or any of the parent directories): .git\n"]}]},{"cell_type":"code","metadata":{"id":"HZID6g2N18Dv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636547790806,"user_tz":-60,"elapsed":533,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"10b924a2-f68c-45ad-ccfa-f2339ecdd3e1"},"source":["%pwd\n","!git branch\n","!git status"],"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["* \u001b[32mmain\u001b[m\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   PT_5.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itCjomxY3joG","executionInfo":{"status":"ok","timestamp":1636545326303,"user_tz":-60,"elapsed":26731,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"cb622354-d284-4a4a-d834-9d6947da152c"},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import math\n","\n","#1\n","def generate_disc_set(nb):\n","  R = 2/math.pi\n","  point = torch.rand(nb,2)*2 -1\n","  # point = torch.empty(nb, 2).uniform_(-1,1) #此法更好！\n","  label = torch.zeros(nb, dtype = torch.int64 )\n","  for i in range(nb):\n","    if (pow(point[i][0], 2) + pow(point[i][1], 2)) <= R:\n","      label[i] = 1\n","    else: \n","      label[i] = 0\n","  #print(label)\n","  #label = F.one_hot(label.to(torch.int64), num_classes= 2)\n","  #print(label)\n","  return point, label\n","\n","print(generate_disc_set(10))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[ 5.4985e-01,  7.3790e-01],\n","        [ 8.2490e-01,  9.8607e-01],\n","        [ 6.4191e-02,  2.2811e-01],\n","        [ 6.1437e-01,  7.7522e-04],\n","        [-3.4236e-01, -4.0201e-01],\n","        [ 3.8588e-01, -7.9124e-01],\n","        [ 3.2723e-01,  7.9248e-01],\n","        [ 5.0853e-01,  7.9748e-01],\n","        [ 8.5438e-01, -1.4900e-01],\n","        [ 6.1822e-01,  9.2721e-01]]), tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 0]))\n"]}]},{"cell_type":"code","metadata":{"id":"bmTwqiYTsWSJ"},"source":["!git add ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iy1wPg3nsdKs","executionInfo":{"status":"ok","timestamp":1636545504390,"user_tz":-60,"elapsed":909,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"662dd58e-1216-4704-fad2-ba423ec69ed6"},"source":["!git commit -m \"first try with colab\"\n","!git config --global user.email \"lai860423@gmail.com\"\n","!git config --global user.name \"lai86423\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main ddb85b5] first try with colab\n"," 1 file changed, 1 insertion(+)\n"," create mode 100644 PT_5.ipynb\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shtxiAS_tWF5","executionInfo":{"status":"ok","timestamp":1636545580979,"user_tz":-60,"elapsed":1049,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"f97e8511-8567-4ca0-9dcc-28470a9f530a"},"source":["https://drive.google.com/drive/folders/1-EjDmQEkJ9Y86ZgwLqVUwgdIqloOcZ5N?usp=sharing\n","!git push origin"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counting objects: 3, done.\n","Delta compression using up to 2 threads.\n","Compressing objects:  33% (1/3)   \rCompressing objects:  66% (2/3)   \rCompressing objects: 100% (3/3)   \rCompressing objects: 100% (3/3), done.\n","Writing objects:  33% (1/3)   \rWriting objects:  66% (2/3)   \rWriting objects: 100% (3/3)   \rWriting objects: 100% (3/3), 6.80 KiB | 1.70 MiB/s, done.\n","Total 3 (delta 0), reused 0 (delta 0)\n","To https://github.com/lai86423/unige_DL_project1.git\n","   4855715..ddb85b5  main -> main\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTLvhnA8NY8s","executionInfo":{"status":"ok","timestamp":1635849232232,"user_tz":-60,"elapsed":348,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"c46fb5c3-9542-45f7-f7f0-5b9ca3186569"},"source":["def Ans_generate_disc_set(nb):\n","  R = 2/math.pi\n","  input = torch.empty(nb, 2).uniform_(-1,1)\n","  print(input, input.pow(2))\n","  #nput.pow(2).sum(1).sub(2 / math.pi).sign().add(1).div(2).long()\n","\n","Ans_generate_disc_set(10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.4795,  0.1335],\n","        [ 0.0927,  0.6165],\n","        [ 0.0592, -0.7543],\n","        [-0.9751, -0.4929],\n","        [-0.8164, -0.0954],\n","        [ 0.7616,  0.4239],\n","        [-0.9248, -0.6412],\n","        [-0.0253, -0.5504],\n","        [ 0.4776,  0.8105],\n","        [ 0.8390,  0.1272]]) tensor([[2.2994e-01, 1.7821e-02],\n","        [8.6014e-03, 3.8009e-01],\n","        [3.5085e-03, 5.6895e-01],\n","        [9.5078e-01, 2.4293e-01],\n","        [6.6645e-01, 9.0948e-03],\n","        [5.8010e-01, 1.7973e-01],\n","        [8.5535e-01, 4.1112e-01],\n","        [6.3822e-04, 3.0290e-01],\n","        [2.2811e-01, 6.5684e-01],\n","        [7.0384e-01, 1.6192e-02]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"UIByX_gpblay"},"source":[" 3. Write\n","\n","create`˙shallow˙model()`\n","\n","that returns a mlp with 2 input units, a single hidden layer of size 128, and 2 output units, \n","\n","and\n","`create˙deep˙model()`\n","\n","that returns a mlp with 2 input units, hidden layers of sizes respectively 4, 8, 16, 32, 64, 128, and 2\n","output units.\n","\n","\n","Hint: You can use the nn.Sequential container to make things simpler. My versions of these two\n","functions are respectively 132 and 355 characters long."]},{"cell_type":"code","metadata":{"id":"d7CS9fbAXYcr"},"source":["#3\n","from torch import nn\n","from torch.nn import functional as F\n","import torch.optim as optim\n","class _shallow_model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(2, 128)\n","        self.fc2 = nn.Linear(128, 2)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","class _deep_model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(2, 4)\n","        self.fc2 = nn.Linear(4, 8)\n","        self.fc3 = nn.Linear(8, 16)\n","        self.fc4 = nn.Linear(16, 32)\n","        self.fc5 = nn.Linear(32, 64)\n","        self.fc6 = nn.Linear(64, 128)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = F.relu(self.fc4(x))\n","        x = F.relu(self.fc5(x))\n","        x = self.fc6(x)\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5zt0ytwUz7p"},"source":["##########Ans\n","\n","def create_shallow_model():\n","    return nn.Sequential(\n","        nn.Linear(2, 128),\n","        nn.ReLU(),\n","        nn.Linear(128, 2)\n","    )\n","\n","def create_deep_model():\n","    return nn.Sequential(\n","        nn.Linear(2, 4),\n","        nn.ReLU(),\n","        nn.Linear(4, 8),\n","        nn.ReLU(),\n","        nn.Linear(8, 16),\n","        nn.ReLU(),\n","        nn.Linear(16, 32),\n","        nn.ReLU(),\n","        nn.Linear(32, 64),\n","        nn.ReLU(),\n","        nn.Linear(64, 128),\n","        nn.ReLU(),\n","        nn.Linear(128, 2)\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-mIzYOLXZMy"},"source":["2. Write functions\n","`train˙model(model, train˙input, train˙target)`\n","\n","compute`˙nb˙errors(model, data˙input, data˙target)`\n","\n","The first should train the model with cross-entropy and 250 epochs of standard sgd with η = 0.1, and\n","mini-batches of size 100.\n","\n","The second should also use mini-batches, and return an integer."]},{"cell_type":"code","metadata":{"id":"FWPbODqh4ThT"},"source":["def compute_nb_errors(model, data_input, data_target, mini_batch_size):\n","  \n","  error = 0\n","  for b in range(0, data_input.size(0), mini_batch_size):\n","    output = model(data_input.narrow(0, b, mini_batch_size))\n","\n","    for i in range(mini_batch_size):\n","      if torch.argmax(output[i]) != data_target[b+i]:\n","        error += 1\n","  acc = 1 - (error/data_input.size(0))\n","  return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXTxxfs_ZKcn"},"source":["#2 \n","def train_model(model, train_input, train_target, mini_batch_size):\n","    # We do this with mini-batches\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=η, momentum=0.3)\n","\n","    for b in range(0, train_input.size(0), mini_batch_size):\n","        #--------------\n","          # torch.narrow(input, dim, start, length) → Tensor\n","        #--------------\n","        output = model(train_input.narrow(0, b, mini_batch_size))#表示取出train_input中第0维上索引从b开始到index+mini_batch_size-1的所有元素\n","        loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n","        model.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    return model, loss "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VhWyk8685QkZ","executionInfo":{"status":"ok","timestamp":1635847981940,"user_tz":-60,"elapsed":8513,"user":{"displayName":"賴映如","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9N3hBM3EPoyWGsML6kFY6ScgQhxsldFteGIJ=s64","userId":"12888536595819061612"}},"outputId":"c4b1d416-2b64-4b3a-c246-6119b9f99abc"},"source":["model = _deep_model()\n","η = 0.2\n","mini_batch_size = 100\n","nb_epochs = 250\n","\n","train_input, train_target = generate_disc_set(1000)\n","test_input, test_target = generate_disc_set(1000)\n","#print(train_input, train_target)\n","for e in range(nb_epochs):\n","    model, acc_loss = train_model(model, train_input, train_target, mini_batch_size)\n","\n","    acc = compute_nb_errors(model, test_input, test_target)\n","    print('epoch :', e, ' loss :', round(acc_loss, 3))\n","    print('acc : ', acc)\n","    print('----------')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch : 0  loss : 33.171\n","acc :  0.5\n","----------\n","epoch : 1  loss : 8.121\n","acc :  0.5\n","----------\n","epoch : 2  loss : 7.813\n","acc :  0.5\n","----------\n","epoch : 3  loss : 7.62\n","acc :  0.5\n","----------\n","epoch : 4  loss : 7.521\n","acc :  0.5\n","----------\n","epoch : 5  loss : 7.45\n","acc :  0.5\n","----------\n","epoch : 6  loss : 7.398\n","acc :  0.5\n","----------\n","epoch : 7  loss : 7.358\n","acc :  0.5\n","----------\n","epoch : 8  loss : 7.326\n","acc :  0.5\n","----------\n","epoch : 9  loss : 7.3\n","acc :  0.5\n","----------\n","epoch : 10  loss : 7.278\n","acc :  0.5\n","----------\n","epoch : 11  loss : 7.259\n","acc :  0.5\n","----------\n","epoch : 12  loss : 7.243\n","acc :  0.5\n","----------\n","epoch : 13  loss : 7.229\n","acc :  0.5\n","----------\n","epoch : 14  loss : 7.217\n","acc :  0.5\n","----------\n","epoch : 15  loss : 7.206\n","acc :  0.5\n","----------\n","epoch : 16  loss : 7.197\n","acc :  0.5\n","----------\n","epoch : 17  loss : 7.188\n","acc :  0.5\n","----------\n","epoch : 18  loss : 7.179\n","acc :  0.5\n","----------\n","epoch : 19  loss : 7.172\n","acc :  0.5\n","----------\n","epoch : 20  loss : 7.166\n","acc :  0.5\n","----------\n","epoch : 21  loss : 7.159\n","acc :  0.5\n","----------\n","epoch : 22  loss : 7.154\n","acc :  0.5\n","----------\n","epoch : 23  loss : 7.149\n","acc :  0.5\n","----------\n","epoch : 24  loss : 7.144\n","acc :  0.5\n","----------\n","epoch : 25  loss : 7.139\n","acc :  0.5\n","----------\n","epoch : 26  loss : 7.135\n","acc :  0.5\n","----------\n","epoch : 27  loss : 7.131\n","acc :  0.5\n","----------\n","epoch : 28  loss : 7.128\n","acc :  0.5\n","----------\n","epoch : 29  loss : 7.124\n","acc :  0.5\n","----------\n","epoch : 30  loss : 7.121\n","acc :  0.5\n","----------\n","epoch : 31  loss : 7.118\n","acc :  0.5\n","----------\n","epoch : 32  loss : 7.115\n","acc :  0.5\n","----------\n","epoch : 33  loss : 7.112\n","acc :  0.5\n","----------\n","epoch : 34  loss : 7.109\n","acc :  0.5\n","----------\n","epoch : 35  loss : 7.107\n","acc :  0.5\n","----------\n","epoch : 36  loss : 7.104\n","acc :  0.5\n","----------\n","epoch : 37  loss : 7.102\n","acc :  0.5\n","----------\n","epoch : 38  loss : 7.1\n","acc :  0.5\n","----------\n","epoch : 39  loss : 7.098\n","acc :  0.5\n","----------\n","epoch : 40  loss : 7.096\n","acc :  0.5\n","----------\n","epoch : 41  loss : 7.094\n","acc :  0.5\n","----------\n","epoch : 42  loss : 7.092\n","acc :  0.5\n","----------\n","epoch : 43  loss : 7.09\n","acc :  0.5\n","----------\n","epoch : 44  loss : 7.088\n","acc :  0.5\n","----------\n","epoch : 45  loss : 7.087\n","acc :  0.5\n","----------\n","epoch : 46  loss : 7.085\n","acc :  0.5\n","----------\n","epoch : 47  loss : 7.083\n","acc :  0.5\n","----------\n","epoch : 48  loss : 7.082\n","acc :  0.5\n","----------\n","epoch : 49  loss : 7.08\n","acc :  0.5\n","----------\n","epoch : 50  loss : 7.079\n","acc :  0.5\n","----------\n","epoch : 51  loss : 7.077\n","acc :  0.5\n","----------\n","epoch : 52  loss : 7.076\n","acc :  0.5\n","----------\n","epoch : 53  loss : 7.074\n","acc :  0.5\n","----------\n","epoch : 54  loss : 7.073\n","acc :  0.5\n","----------\n","epoch : 55  loss : 7.071\n","acc :  0.5\n","----------\n","epoch : 56  loss : 7.07\n","acc :  0.5\n","----------\n","epoch : 57  loss : 7.068\n","acc :  0.5\n","----------\n","epoch : 58  loss : 7.067\n","acc :  0.5\n","----------\n","epoch : 59  loss : 7.066\n","acc :  0.5\n","----------\n","epoch : 60  loss : 7.064\n","acc :  0.5\n","----------\n","epoch : 61  loss : 7.063\n","acc :  0.5\n","----------\n","epoch : 62  loss : 7.061\n","acc :  0.5\n","----------\n","epoch : 63  loss : 7.059\n","acc :  0.5\n","----------\n","epoch : 64  loss : 7.058\n","acc :  0.5\n","----------\n","epoch : 65  loss : 7.056\n","acc :  0.5\n","----------\n","epoch : 66  loss : 7.054\n","acc :  0.5\n","----------\n","epoch : 67  loss : 7.052\n","acc :  0.5\n","----------\n","epoch : 68  loss : 7.05\n","acc :  0.5\n","----------\n","epoch : 69  loss : 7.048\n","acc :  0.5\n","----------\n","epoch : 70  loss : 7.045\n","acc :  0.5\n","----------\n","epoch : 71  loss : 7.042\n","acc :  0.5\n","----------\n","epoch : 72  loss : 7.039\n","acc :  0.5\n","----------\n","epoch : 73  loss : 7.035\n","acc :  0.5\n","----------\n","epoch : 74  loss : 7.03\n","acc :  0.5\n","----------\n","epoch : 75  loss : 7.025\n","acc :  0.5\n","----------\n","epoch : 76  loss : 7.018\n","acc :  0.5\n","----------\n","epoch : 77  loss : 7.009\n","acc :  0.5\n","----------\n","epoch : 78  loss : 6.998\n","acc :  0.5\n","----------\n","epoch : 79  loss : 6.984\n","acc :  0.5\n","----------\n","epoch : 80  loss : 6.964\n","acc :  0.5\n","----------\n","epoch : 81  loss : 6.936\n","acc :  0.5\n","----------\n","epoch : 82  loss : 6.898\n","acc :  0.5\n","----------\n","epoch : 83  loss : 6.844\n","acc :  0.5\n","----------\n","epoch : 84  loss : 6.769\n","acc :  0.5\n","----------\n","epoch : 85  loss : 6.672\n","acc :  0.529\n","----------\n","epoch : 86  loss : 6.548\n","acc :  0.649\n","----------\n","epoch : 87  loss : 6.39\n","acc :  0.692\n","----------\n","epoch : 88  loss : 6.178\n","acc :  0.7170000000000001\n","----------\n","epoch : 89  loss : 5.978\n","acc :  0.727\n","----------\n","epoch : 90  loss : 5.9\n","acc :  0.733\n","----------\n","epoch : 91  loss : 5.687\n","acc :  0.727\n","----------\n","epoch : 92  loss : 5.563\n","acc :  0.727\n","----------\n","epoch : 93  loss : 5.455\n","acc :  0.732\n","----------\n","epoch : 94  loss : 5.361\n","acc :  0.733\n","----------\n","epoch : 95  loss : 5.285\n","acc :  0.736\n","----------\n","epoch : 96  loss : 5.194\n","acc :  0.748\n","----------\n","epoch : 97  loss : 5.1\n","acc :  0.76\n","----------\n","epoch : 98  loss : 5.045\n","acc :  0.769\n","----------\n","epoch : 99  loss : 4.804\n","acc :  0.779\n","----------\n","epoch : 100  loss : 4.706\n","acc :  0.794\n","----------\n","epoch : 101  loss : 4.575\n","acc :  0.812\n","----------\n","epoch : 102  loss : 4.425\n","acc :  0.817\n","----------\n","epoch : 103  loss : 4.365\n","acc :  0.831\n","----------\n","epoch : 104  loss : 4.302\n","acc :  0.858\n","----------\n","epoch : 105  loss : 4.323\n","acc :  0.856\n","----------\n","epoch : 106  loss : 4.192\n","acc :  0.862\n","----------\n","epoch : 107  loss : 4.542\n","acc :  0.882\n","----------\n","epoch : 108  loss : 4.032\n","acc :  0.894\n","----------\n","epoch : 109  loss : 4.286\n","acc :  0.898\n","----------\n","epoch : 110  loss : 4.128\n","acc :  0.913\n","----------\n","epoch : 111  loss : 4.014\n","acc :  0.914\n","----------\n","epoch : 112  loss : 3.986\n","acc :  0.916\n","----------\n","epoch : 113  loss : 3.789\n","acc :  0.925\n","----------\n","epoch : 114  loss : 3.496\n","acc :  0.92\n","----------\n","epoch : 115  loss : 3.56\n","acc :  0.921\n","----------\n","epoch : 116  loss : 3.284\n","acc :  0.924\n","----------\n","epoch : 117  loss : 3.344\n","acc :  0.923\n","----------\n","epoch : 118  loss : 3.099\n","acc :  0.924\n","----------\n","epoch : 119  loss : 3.394\n","acc :  0.921\n","----------\n","epoch : 120  loss : 2.868\n","acc :  0.923\n","----------\n","epoch : 121  loss : 3.126\n","acc :  0.922\n","----------\n","epoch : 122  loss : 2.672\n","acc :  0.927\n","----------\n","epoch : 123  loss : 3.189\n","acc :  0.923\n","----------\n","epoch : 124  loss : 2.528\n","acc :  0.929\n","----------\n","epoch : 125  loss : 3.092\n","acc :  0.922\n","----------\n","epoch : 126  loss : 2.464\n","acc :  0.9299999999999999\n","----------\n","epoch : 127  loss : 3.206\n","acc :  0.927\n","----------\n","epoch : 128  loss : 2.306\n","acc :  0.9339999999999999\n","----------\n","epoch : 129  loss : 3.225\n","acc :  0.929\n","----------\n","epoch : 130  loss : 2.272\n","acc :  0.9299999999999999\n","----------\n","epoch : 131  loss : 3.144\n","acc :  0.9359999999999999\n","----------\n","epoch : 132  loss : 2.069\n","acc :  0.931\n","----------\n","epoch : 133  loss : 2.96\n","acc :  0.9390000000000001\n","----------\n","epoch : 134  loss : 2.192\n","acc :  0.924\n","----------\n","epoch : 135  loss : 2.695\n","acc :  0.94\n","----------\n","epoch : 136  loss : 2.248\n","acc :  0.924\n","----------\n","epoch : 137  loss : 2.397\n","acc :  0.918\n","----------\n","epoch : 138  loss : 2.067\n","acc :  0.926\n","----------\n","epoch : 139  loss : 2.406\n","acc :  0.915\n","----------\n","epoch : 140  loss : 2.151\n","acc :  0.922\n","----------\n","epoch : 141  loss : 2.227\n","acc :  0.921\n","----------\n","epoch : 142  loss : 2.048\n","acc :  0.924\n","----------\n","epoch : 143  loss : 2.273\n","acc :  0.921\n","----------\n","epoch : 144  loss : 1.981\n","acc :  0.925\n","----------\n","epoch : 145  loss : 2.323\n","acc :  0.921\n","----------\n","epoch : 146  loss : 1.843\n","acc :  0.9339999999999999\n","----------\n","epoch : 147  loss : 2.57\n","acc :  0.925\n","----------\n","epoch : 148  loss : 1.537\n","acc :  0.957\n","----------\n","epoch : 149  loss : 2.421\n","acc :  0.926\n","----------\n","epoch : 150  loss : 1.513\n","acc :  0.952\n","----------\n","epoch : 151  loss : 2.255\n","acc :  0.924\n","----------\n","epoch : 152  loss : 1.611\n","acc :  0.945\n","----------\n","epoch : 153  loss : 2.161\n","acc :  0.926\n","----------\n","epoch : 154  loss : 1.784\n","acc :  0.937\n","----------\n","epoch : 155  loss : 1.934\n","acc :  0.935\n","----------\n","epoch : 156  loss : 1.748\n","acc :  0.942\n","----------\n","epoch : 157  loss : 1.883\n","acc :  0.94\n","----------\n","epoch : 158  loss : 1.614\n","acc :  0.947\n","----------\n","epoch : 159  loss : 1.923\n","acc :  0.94\n","----------\n","epoch : 160  loss : 1.585\n","acc :  0.945\n","----------\n","epoch : 161  loss : 1.908\n","acc :  0.942\n","----------\n","epoch : 162  loss : 1.573\n","acc :  0.945\n","----------\n","epoch : 163  loss : 1.755\n","acc :  0.946\n","----------\n","epoch : 164  loss : 1.688\n","acc :  0.944\n","----------\n","epoch : 165  loss : 1.751\n","acc :  0.947\n","----------\n","epoch : 166  loss : 1.667\n","acc :  0.947\n","----------\n","epoch : 167  loss : 1.575\n","acc :  0.947\n","----------\n","epoch : 168  loss : 1.691\n","acc :  0.949\n","----------\n","epoch : 169  loss : 1.517\n","acc :  0.947\n","----------\n","epoch : 170  loss : 1.733\n","acc :  0.948\n","----------\n","epoch : 171  loss : 1.469\n","acc :  0.948\n","----------\n","epoch : 172  loss : 1.781\n","acc :  0.947\n","----------\n","epoch : 173  loss : 1.394\n","acc :  0.958\n","----------\n","epoch : 174  loss : 1.527\n","acc :  0.948\n","----------\n","epoch : 175  loss : 1.511\n","acc :  0.947\n","----------\n","epoch : 176  loss : 1.532\n","acc :  0.949\n","----------\n","epoch : 177  loss : 1.612\n","acc :  0.95\n","----------\n","epoch : 178  loss : 1.585\n","acc :  0.943\n","----------\n","epoch : 179  loss : 1.476\n","acc :  0.949\n","----------\n","epoch : 180  loss : 1.428\n","acc :  0.952\n","----------\n","epoch : 181  loss : 1.567\n","acc :  0.944\n","----------\n","epoch : 182  loss : 1.346\n","acc :  0.953\n","----------\n","epoch : 183  loss : 1.394\n","acc :  0.949\n","----------\n","epoch : 184  loss : 1.325\n","acc :  0.957\n","----------\n","epoch : 185  loss : 1.259\n","acc :  0.948\n","----------\n","epoch : 186  loss : 1.234\n","acc :  0.949\n","----------\n","epoch : 187  loss : 1.31\n","acc :  0.949\n","----------\n","epoch : 188  loss : 1.25\n","acc :  0.948\n","----------\n","epoch : 189  loss : 1.33\n","acc :  0.946\n","----------\n","epoch : 190  loss : 1.178\n","acc :  0.948\n","----------\n","epoch : 191  loss : 1.273\n","acc :  0.951\n","----------\n","epoch : 192  loss : 1.107\n","acc :  0.949\n","----------\n","epoch : 193  loss : 1.636\n","acc :  0.938\n","----------\n","epoch : 194  loss : 1.011\n","acc :  0.949\n","----------\n","epoch : 195  loss : 1.661\n","acc :  0.944\n","----------\n","epoch : 196  loss : 1.066\n","acc :  0.95\n","----------\n","epoch : 197  loss : 1.383\n","acc :  0.948\n","----------\n","epoch : 198  loss : 1.272\n","acc :  0.95\n","----------\n","epoch : 199  loss : 1.186\n","acc :  0.952\n","----------\n","epoch : 200  loss : 1.121\n","acc :  0.951\n","----------\n","epoch : 201  loss : 1.505\n","acc :  0.942\n","----------\n","epoch : 202  loss : 0.941\n","acc :  0.955\n","----------\n","epoch : 203  loss : 1.488\n","acc :  0.95\n","----------\n","epoch : 204  loss : 0.918\n","acc :  0.954\n","----------\n","epoch : 205  loss : 1.389\n","acc :  0.955\n","----------\n","epoch : 206  loss : 1.164\n","acc :  0.944\n","----------\n","epoch : 207  loss : 1.192\n","acc :  0.952\n","----------\n","epoch : 208  loss : 0.925\n","acc :  0.953\n","----------\n","epoch : 209  loss : 1.515\n","acc :  0.94\n","----------\n","epoch : 210  loss : 1.064\n","acc :  0.946\n","----------\n","epoch : 211  loss : 1.536\n","acc :  0.945\n","----------\n","epoch : 212  loss : 1.205\n","acc :  0.95\n","----------\n","epoch : 213  loss : 1.276\n","acc :  0.95\n","----------\n","epoch : 214  loss : 1.398\n","acc :  0.945\n","----------\n","epoch : 215  loss : 1.281\n","acc :  0.949\n","----------\n","epoch : 216  loss : 1.31\n","acc :  0.95\n","----------\n","epoch : 217  loss : 0.915\n","acc :  0.955\n","----------\n","epoch : 218  loss : 1.33\n","acc :  0.957\n","----------\n","epoch : 219  loss : 1.079\n","acc :  0.942\n","----------\n","epoch : 220  loss : 1.375\n","acc :  0.942\n","----------\n","epoch : 221  loss : 1.04\n","acc :  0.949\n","----------\n","epoch : 222  loss : 1.169\n","acc :  0.948\n","----------\n","epoch : 223  loss : 0.988\n","acc :  0.951\n","----------\n","epoch : 224  loss : 1.109\n","acc :  0.957\n","----------\n","epoch : 225  loss : 1.064\n","acc :  0.951\n","----------\n","epoch : 226  loss : 1.141\n","acc :  0.95\n","----------\n","epoch : 227  loss : 0.927\n","acc :  0.952\n","----------\n","epoch : 228  loss : 1.634\n","acc :  0.943\n","----------\n","epoch : 229  loss : 0.914\n","acc :  0.952\n","----------\n","epoch : 230  loss : 1.111\n","acc :  0.95\n","----------\n","epoch : 231  loss : 1.173\n","acc :  0.95\n","----------\n","epoch : 232  loss : 1.147\n","acc :  0.953\n","----------\n","epoch : 233  loss : 0.776\n","acc :  0.962\n","----------\n","epoch : 234  loss : 0.948\n","acc :  0.953\n","----------\n","epoch : 235  loss : 2.016\n","acc :  0.945\n","----------\n","epoch : 236  loss : 0.891\n","acc :  0.954\n","----------\n","epoch : 237  loss : 0.999\n","acc :  0.952\n","----------\n","epoch : 238  loss : 0.925\n","acc :  0.953\n","----------\n","epoch : 239  loss : 1.199\n","acc :  0.951\n","----------\n","epoch : 240  loss : 0.983\n","acc :  0.957\n","----------\n","epoch : 241  loss : 1.099\n","acc :  0.953\n","----------\n","epoch : 242  loss : 0.929\n","acc :  0.951\n","----------\n","epoch : 243  loss : 1.502\n","acc :  0.948\n","----------\n","epoch : 244  loss : 1.009\n","acc :  0.931\n","----------\n","epoch : 245  loss : 1.767\n","acc :  0.94\n","----------\n","epoch : 246  loss : 1.0\n","acc :  0.952\n","----------\n","epoch : 247  loss : 0.812\n","acc :  0.958\n","----------\n","epoch : 248  loss : 1.065\n","acc :  0.954\n","----------\n","epoch : 249  loss : 0.849\n","acc :  0.957\n","----------\n"]}]}]}