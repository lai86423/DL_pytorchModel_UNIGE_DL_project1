# -*- coding: utf-8 -*-
"""project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gu3Lp3RHboUFOcB2WhOLiB4VIKaWMfmt
"""

import torch
from torch import nn
from torch.nn import functional as F
import torch.optim as optim
import math

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        nb_hidden = 200
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)
        self.fc1 = nn.Linear(5*5 * 64, nb_hidden)
        self.fc2 = nn.Linear(nb_hidden, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))
        x = F.relu(self.fc1(x.view(-1, 5*5 * 64)))
        x = self.fc2(x)
        # print("x = ",x.size(), x)
        return x

#2 
def train_model(model, train_input, train_target, mini_batch_size):
    # We do this with mini-batches
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=η, momentum=0.3)
    # print("Size = ", train_input.size(), train_target.size())
    acc_loss = 0
    for b in range(0, train_input.size(0), mini_batch_size):
        #--------------
          # torch.narrow(input, dim, start, length) → Tensor
        #--------------
        # print("train_input.narrow",train_input.narrow(0, b, mini_batch_size).size())
        output = model(train_input.narrow(0, b, mini_batch_size))#表示取出train_input中第0维上索引从b开始到index+mini_batch_size-1的所有元素
        loss = criterion(output, train_target.narrow(0, b, mini_batch_size))
        acc_loss = acc_loss + loss.item()
        model.zero_grad()
        loss.backward()
        optimizer.step()

    return model, acc_loss

import dlc_practical_prologue as prologue
N = 1000
data = prologue.generate_pair_sets(N)
train_data = data[:3]
test_data = data[3:]

train_input, train_target, train_classes = train_data[0], train_data[1], train_data[2]
test_input, test_target, test_classes = test_data[0], test_data[1], test_data[2]
print(train_input.size(), train_target.size(), train_classes.size())

train_input_1 =  train_input[:,0].unsqueeze(1)
train_input_2 =  train_input[:,1].unsqueeze(1)
train_classes_1 =  train_classes[:,0]
train_classes_2 =  train_classes[:,1]
train_target_2 =  train_classes[:,1]
test_input_1 =  test_input[:,0].unsqueeze(1)
test_input_2 =  test_input[:,1].unsqueeze(1)
test_classes_1 =  test_classes[:,0]
test_classes_2 =  test_classes[:,1]
print(test_input_1.size(), test_classes_1.size(),test_classes_1[1])

def compute_nb_errors(model, data_input, data_target, mini_batch_size):
  error = 0
  output_class = torch.ones(data_input.size(0))
  for b in range(0, data_input.size(0), mini_batch_size): 
    output = model(data_input.narrow(0, b, mini_batch_size))
    
    for i in range(mini_batch_size): 
      output_class[b+i] = torch.argmax(output[i])
      if output_class[b+i] != data_target[b+i]:
        error += 1
  acc = 1 - (error/data_input.size(0))
  return acc, output_class

model = Net()
η = 0.002 #If it too big, it will fail!
mini_batch_size = 50
nb_epochs =30
#print(train_input, train_target)
for e in range(nb_epochs):
  
    #print(train_input_1, train_classes_1)
    model, acc_loss = train_model(model, train_input_1, train_classes_1, mini_batch_size)
    acc, output_class_1 = compute_nb_errors(model, test_input_1, test_classes_1, mini_batch_size)
    print('epoch :', e, ' loss :', round(acc_loss))
    print('acc : ', acc)
    print('----------')

for e in range(nb_epochs):
    model, acc_loss = train_model(model, train_input_2, train_classes_2, mini_batch_size)
    acc, output_class_2 = compute_nb_errors(model, test_input_2, test_classes_2, mini_batch_size)
    print('epoch :', e, ' loss :', round(acc_loss))
    print('acc : ', acc)
    print('----------')

def compute_num_errors(data_input1, data_input2, data_target, mini_batch_size):
  error = 0
  for b in range(0, data_input.size(0), mini_batch_size): 
    for i in range(mini_batch_size): 
      
      if torch.argmax(output[i]) != data_target[b+i]:
        error += 1
  acc = 1 - (error/data_input.size(0))
  return acc

def predict_target(data_output1, data_output2):
  output = torch.ones(len(data_output1))
  for i in range(len(data_output1)):
    #print(data_output1[i])
    if data_output1[i].item() > data_output2[i].item():
        output[i] = 0
    else:
        output[i] = 1
  return output

target_output = predict_target(output_class_1, output_class_2)
print(target_output, target_output.size())

for e in range(nb_epochs):
    model, acc_loss = train_model(model, train_input_2, train_classes_2, mini_batch_size)
    acc = compute_nb_errors(model, test_input_2, test_classes_2, mini_batch_size)
    print('epoch :', e, ' loss :', round(acc_loss))
    print('acc : ', acc)
    print('----------')

model1 = Net()
model2 = Net()
η = 0.2
mini_batch_size = 2
nb_epochs = 25
#print(train_input, train_target)
for e in range(nb_epochs):
    print("Data = ", train_data[0].size(), train_data[2].size())
    model, acc_loss = train_model(model1, train_data[0][0], train_data[2][0], mini_batch_size)

    acc = compute_nb_errors(model, test_input, test_target)
    print('epoch :', e, ' loss :', round(acc_loss, 3))
    print('acc : ', acc)
    print('----------')

for e in range(nb_epochs):
    model, acc_loss = train_model(model2, train_data[0][1], train_data[2][1], mini_batch_size)

    acc = compute_nb_errors(model, test_input, test_target)
    print('epoch :', e, ' loss :', round(acc_loss, 3))
    print('acc : ', acc)
    print('----------')

class Net2(nn.Module):
    def __init__(self):
        super().__init__()
        nb_hidden = 200
        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)
        self.conv2 = nn.Conv2d(2*32, 2*32, kernel_size=5)
        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)
        self.fc1 = nn.Linear(9 * 64, nb_hidden)
        self.fc2 = nn.Linear(nb_hidden, 10)

    def forward(self, x):
        x1 = x[0]
        print("x1= ", x1)
        x1 = F.relu(F.max_pool2d(self.conv1(x1), kernel_size=2))
        x1 = F.relu(F.max_pool2d(self.conv2(x1), kernel_size=2))
        x1 = F.relu(self.conv3(x1))
        x1 = F.relu(self.fc1(x1.view(-1, 9 * 64)))
        x1 = self.fc2(x1)
        x2 = x[1]
        x2 = F.relu(F.max_pool2d(self.conv1(x2), kernel_size=2))
        x2 = F.relu(F.max_pool2d(self.conv2(x2), kernel_size=2))
        x2 = F.relu(self.conv3(x2))
        x2 = F.relu(self.fc1(x2.view(-1, 9 * 64)))
        x2 = self.fc2(x2)
        y = [x1, x2]
        return y

