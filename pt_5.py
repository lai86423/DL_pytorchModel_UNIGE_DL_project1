# -*- coding: utf-8 -*-
"""PT_5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OPdEfIv-im9pyEwvFfAvDYSC68UK71Q-
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive # import drive from google colab

ROOT = "/content/drive"     # default location for the drive
print(ROOT)                 # print content of ROOT (Optional)

drive.mount(ROOT)    

# %cd '/content/drive/My Drive/UNIGE/Course/Deep Learning/final project/'
# %pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/UNIGE/Course/Deep Learning/final project/

# Commented out IPython magic to ensure Python compatibility.
# %ls

# Clone github repository setup
# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH
from os.path import join  

# path to your project on Google Drive
MY_GOOGLE_DRIVE_PATH = '/content/drive/My Drive/UNIGE/Course/Deep Learning/final project/unige_DL_project1/' 
# replace with your Github username 
GIT_USERNAME = "lai86423" 
# definitely replace with your
GIT_TOKEN = "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"  
# Replace with your github repository in this case we want 
# to clone deep-learning-v2-pytorch repository
GIT_REPOSITORY = "unige_DL_project1" 

PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)

# It's good to print out the value if you are not sure 
print("PROJECT_PATH: ", PROJECT_PATH)   

# In case we haven't created the folder already; we will create a folder in the project path 
!mkdir "{PROJECT_PATH}"    

#GIT_PATH = "https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git" this return 400 Bad Request for me
GIT_PATH = "https://" + GIT_TOKEN + "@github.com/" + GIT_USERNAME + "/" + GIT_REPOSITORY + ".git"
print("GIT_PATH: ", GIT_PATH)

# Clone github repository setup
# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH
from os.path import join  

# path to your project on Google Drive
MY_GOOGLE_DRIVE_PATH = 'https://drive.google.com/drive/folders/1-EjDmQEkJ9Y86ZgwLqVUwgdIqloOcZ5N?usp=sharing' 
# replace with your Github username 
GIT_USERNAME = "lai86423" 
# definitely replace with your
GIT_TOKEN = "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"  
# Replace with your github repository in this case we want 
# to clone deep-learning-v2-pytorch repository
GIT_REPOSITORY = "unige_DL_project1" 

PROJECT_PATH = 'https://drive.google.com/drive/folders/1-EjDmQEkJ9Y86ZgwLqVUwgdIqloOcZ5N?usp=sharing' 

# It's good to print out the value if you are not sure 
print("PROJECT_PATH: ", PROJECT_PATH)   

# In case we haven't created the folder already; we will create a folder in the project path 
!mkdir "{PROJECT_PATH}"    

#GIT_PATH = "https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git" this return 400 Bad Request for me
GIT_PATH = "https://" + GIT_TOKEN + "@github.com/" + GIT_USERNAME + "/" + GIT_REPOSITORY + ".git"
print("GIT_PATH: ", GIT_PATH)

# Commented out IPython magic to ensure Python compatibility.
#%cd "{PROJECT_PATH}"
#%cd '/unige_DL_project_1'   # Change directory to the location defined in project_path\
# %cd "{PROJECT_PATH}"    # Change directory to the location defined in project_path
!git clone "{GIT_PATH}" # clone the github repository

!git remote add YingRu "{PROJECT_PATH}"

!git remote -v

# Commented out IPython magic to ensure Python compatibility.
# %cd "{PROJECT_PATH}" 
# %pwd
!git branch
!git status

# Commented out IPython magic to ensure Python compatibility.
# %pwd
!git branch
!git status

!git add .

!git remote

import torch
from torch import nn
import torch.nn.functional as F
import math

#1
def generate_disc_set(nb):
  R = 2/math.pi
  point = torch.rand(nb,2)*2 -1
  # point = torch.empty(nb, 2).uniform_(-1,1) #此法更好！
  label = torch.zeros(nb, dtype = torch.int64 )
  for i in range(nb):
    if (pow(point[i][0], 2) + pow(point[i][1], 2)) <= R:
      label[i] = 1
    else: 
      label[i] = 0
  #print(label)
  #label = F.one_hot(label.to(torch.int64), num_classes= 2)
  #print(label)
  return point, label

print(generate_disc_set(10))

!git clone "{GIT_PATH}"

!git add .

!git commit -m "first try with colab"
!git config --global user.email "lai860423@gmail.com"
!git config --global user.name "lai86423"

!git commit -m "cowork try with colab"
!git config --global user.email "h6101717@gmail.com"
!git config --global user.name "h6101717"

!git push origin

def Ans_generate_disc_set(nb):
  R = 2/math.pi
  input = torch.empty(nb, 2).uniform_(-1,1)
  print(input, input.pow(2))
  #nput.pow(2).sum(1).sub(2 / math.pi).sign().add(1).div(2).long()

Ans_generate_disc_set(10)

""" 3. Write

create`˙shallow˙model()`

that returns a mlp with 2 input units, a single hidden layer of size 128, and 2 output units, 

and
`create˙deep˙model()`

that returns a mlp with 2 input units, hidden layers of sizes respectively 4, 8, 16, 32, 64, 128, and 2
output units.


Hint: You can use the nn.Sequential container to make things simpler. My versions of these two
functions are respectively 132 and 355 characters long.
"""

#3
from torch import nn
from torch.nn import functional as F
import torch.optim as optim
class _shallow_model(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(2, 128)
        self.fc2 = nn.Linear(128, 2)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

class _deep_model(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(2, 4)
        self.fc2 = nn.Linear(4, 8)
        self.fc3 = nn.Linear(8, 16)
        self.fc4 = nn.Linear(16, 32)
        self.fc5 = nn.Linear(32, 64)
        self.fc6 = nn.Linear(64, 128)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = F.relu(self.fc4(x))
        x = F.relu(self.fc5(x))
        x = self.fc6(x)
        return x

##########Ans

def create_shallow_model():
    return nn.Sequential(
        nn.Linear(2, 128),
        nn.ReLU(),
        nn.Linear(128, 2)
    )

def create_deep_model():
    return nn.Sequential(
        nn.Linear(2, 4),
        nn.ReLU(),
        nn.Linear(4, 8),
        nn.ReLU(),
        nn.Linear(8, 16),
        nn.ReLU(),
        nn.Linear(16, 32),
        nn.ReLU(),
        nn.Linear(32, 64),
        nn.ReLU(),
        nn.Linear(64, 128),
        nn.ReLU(),
        nn.Linear(128, 2)
    )

"""2. Write functions
`train˙model(model, train˙input, train˙target)`

compute`˙nb˙errors(model, data˙input, data˙target)`

The first should train the model with cross-entropy and 250 epochs of standard sgd with η = 0.1, and
mini-batches of size 100.

The second should also use mini-batches, and return an integer.
"""

def compute_nb_errors(model, data_input, data_target, mini_batch_size):
  
  error = 0
  for b in range(0, data_input.size(0), mini_batch_size):
    output = model(data_input.narrow(0, b, mini_batch_size))

    for i in range(mini_batch_size):
      if torch.argmax(output[i]) != data_target[b+i]:
        error += 1
  acc = 1 - (error/data_input.size(0))
  return acc

#2 
def train_model(model, train_input, train_target, mini_batch_size):
    # We do this with mini-batches
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=η, momentum=0.3)

    for b in range(0, train_input.size(0), mini_batch_size):
        #--------------
          # torch.narrow(input, dim, start, length) → Tensor
        #--------------
        output = model(train_input.narrow(0, b, mini_batch_size))#表示取出train_input中第0维上索引从b开始到index+mini_batch_size-1的所有元素
        loss = criterion(output, train_target.narrow(0, b, mini_batch_size))
        model.zero_grad()
        loss.backward()
        optimizer.step()

    return model, loss

model = _deep_model()
η = 0.2
mini_batch_size = 100
nb_epochs = 250

train_input, train_target = generate_disc_set(1000)
test_input, test_target = generate_disc_set(1000)
#print(train_input, train_target)
for e in range(nb_epochs):
    model, acc_loss = train_model(model, train_input, train_target, mini_batch_size)

    acc = compute_nb_errors(model, test_input, test_target)
    print('epoch :', e, ' loss :', round(acc_loss, 3))
    print('acc : ', acc)
    print('----------')